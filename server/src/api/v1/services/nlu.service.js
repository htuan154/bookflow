'use strict';

const { fetch } = require('undici'); 

const OLLAMA_URL = process.env.OLLAMA_BASE_URL || 'http://127.0.0.1:11434';
const OLLAMA_MODEL = process.env.OLLAMA_MODEL || 'qwen2.5:3b-instruct';

function normalize(text = '') {
  return String(text)
    .normalize('NFD')
    .replace(/\p{Diacritic}/gu, '')
    .replace(/ƒë/gi, 'd')
    .toLowerCase()
    .trim();
}

async function analyzeWithLLM(text, context = {}) {
    const { last_city, last_entity } = context;

    // üî• PROMPT ƒê∆Ø·ª¢C TINH CH·ªàNH ƒê·ªÇ S·ª¨A 3 L·ªñI TR√äN
    const prompt = `
    B·∫°n l√† chuy√™n gia ng√¥n ng·ªØ du l·ªãch Vi·ªát Nam.
    
    INPUT: "${text}"
    CONTEXT: City="${last_city || '?'}", Entity="${last_entity || '?'}"

    NHI·ªÜM V·ª§:
    1. search_term (QUAN TR·ªåNG): 
       - Kh√¥i ph·ª•c d·∫•u ti·∫øng Vi·ªát chu·∫©n x√°c cho ƒë·ªãa danh.
       - VD: "duong ham dieu khac" -> "ƒê∆∞·ªùng H·∫ßm ƒêi√™u Kh·∫Øc".
       - VD: "da nag" -> "ƒê√† N·∫µng".
       - Gi·ªØ nguy√™n t√™n ri√™ng, b·ªè c√°c t·ª´ th·ª´a.
    
    2. rewritten: Vi·∫øt l·∫°i c√¢u h·ªèi t·ª± nhi√™n.

    3. city: T√™n th√†nh ph·ªë hi·ªán t·∫°i.

    4. intent (Ph√¢n lo·∫°i th·∫≠t k·ªπ):
       - "ask_hotels": CH·ªà KHI user h·ªèi t√¨m n∆°i ·ªü, kh√°ch s·∫°n, resort, homestay, ƒë·∫∑t ph√≤ng.
         (L∆ØU √ù: "check-in" t·∫°i ƒë·ªãa ƒëi·ªÉm tham quan nh∆∞ c·∫ßu, h·ªì, n√∫i -> L√Ä "ask_places", KH√îNG PH·∫¢I "ask_hotels").
       - "ask_promotions": H·ªèi khuy·∫øn m√£i, voucher, gi·∫£m gi√°.
       - "ask_weather": H·ªèi th·ªùi ti·∫øt.
       - "ask_places": H·ªèi ch·ªó ch∆°i, tham quan, ƒÉn u·ªëng, ho·∫∑c "check-in" ƒë·ªãa danh.
       - "ask_details": H·ªèi chi ti·∫øt (gi√° v√©, ƒë·ªãa ch·ªâ) v·ªÅ 1 ƒë·ªãa ƒëi·ªÉm c·ª• th·ªÉ.
       - "chitchat": X√£ giao.

    5. filters: amenities (ti·ªán √≠ch), time_ref (th·ªùi gian).

    JSON OUTPUT FORMAT:
    {
       "search_term": "...",
       "rewritten": "...",
       "city": "...",
       "intent": "...",
       "amenities": [],
       "time_ref": null
    }
    `;

    try {
        const res = await fetch(`${OLLAMA_URL}/api/generate`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model: OLLAMA_MODEL,
                prompt: prompt,
                stream: false,
                format: "json",
                options: { temperature: 0.1 } 
            })
        });

        const data = await res.json();
        let result;
        try {
            result = JSON.parse(data.response);
        } catch (err) {
            return { 
                search_term: text, 
                rewritten: text, 
                city: last_city, 
                intent: 'ask_places', 
                amenities: [], 
                time_ref: null 
            };
        }

        return { 
            search_term: result.search_term || text, 
            rewritten: result.rewritten || text,     
            city: result.city || last_city, 
            intent: result.intent || 'ask_places',
            amenities: Array.isArray(result.amenities) ? result.amenities : [],
            time_ref: result.time_ref || null
        };

    } catch (e) {
        return { search_term: text, rewritten: text, city: last_city, intent: 'other', amenities: [], time_ref: null };
    }
}

async function analyzeAsync(message = '', contextState = {}) {
  const aiResult = await analyzeWithLLM(message, contextState);
  
  let finalIntent = aiResult.intent;
  if (finalIntent === 'ask_details' && !contextState.last_entity && message.length < 4) {
      finalIntent = 'chitchat';
  }

  return {
    original: message,
    normalized: normalize(aiResult.search_term),
    rewritten: aiResult.rewritten,
    search_term: aiResult.search_term, 
    intent: finalIntent,
    city: aiResult.city, 
    amenities: aiResult.amenities, 
    time_ref: aiResult.time_ref,   
    category: finalIntent === 'ask_weather' ? 'weather' : 'place'
  };
}

module.exports = { analyzeAsync, normalize };